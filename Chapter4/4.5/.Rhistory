library(tidyverse)
library(lme4)
library(ggsignif)
eng <- read_tsv('eng-regression.txt')
chi <- read_tsv('chi-regression.txt')
grk <- read_tsv('grk-regression.txt')
jap <- read_tsv('jap-regression.txt')
eng_tidy <- eng %>%
mutate(lang = 'eng')
chi_tidy <- chi %>%
mutate(lang = 'chi')
grk_tidy <- grk %>%
mutate(lang = 'grk')
jap_tidy <-jap %>%
mutate(lang = 'jap')
data <-  eng_tidy %>%
full_join(grk_tidy) %>%
full_join(chi_tidy) %>%
full_join(jap_tidy)
predictors <- data %>%
select(freqToken, freqType, flToken, flType)
cor(predictors)
#These are AWESOME results#
m0 = lmer(accuracy ~ freqToken + complexity + (1|lang) + (1|consonant), data=data)
summary(m0)
#These are AWESOME results#
m0 = lmer(accuracy ~ freqToken + complexity + (1|lang) + (1|consonant), data=data)
summary(m0)
m0 = lmer(accuracy ~ freqType + complexity + (1|lang) + (1|consonant), data=data)
summary(m0)
#These are AWESOME results#
m0 = lmer(accuracy ~ freqToken + complexity + (1|lang) + (1|consonant), data=data)
summary(m0)
lang = eng_tidy
m1 = lm(accuracy ~ flType + complexity, data=lang)
summary(m1)
eng <- read_tsv('eng-new-regression.txt')
lang = eng_tidy
m1 = lm(accuracy ~ flType + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ flToken + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ freqType + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ freqToken + complexity, data=lang)
summary(m1)
eng <- read_tsv('eng-new-regression.txt')
eng_tidy <- eng %>%
mutate(lang = 'eng')
data <-  eng_tidy %>%
full_join(grk_tidy) %>%
full_join(chi_tidy) %>%
full_join(jap_tidy)
predictors <- data %>%
select(freqToken, freqType, flToken, flType)
cor(predictors)
lang = eng_tidy
m1 = lm(accuracy ~ flType + complexity, data=lang)
summary(m1)
lang = eng_tidy
m1 = lm(accuracy ~ flType + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ flToken + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ freqType + complexity, data=lang)
summary(m1)
m1 = lm(accuracy ~ freqToken + complexity, data=lang)
summary(m1)
setwd("~/Documents/GitHub2/Functionalism_Contrast_Change/Chapter4")
library(tidyverse)
library(lme4)
eng_measures <- read_tsv('eng-regression.txt')
chi_measures <- read_tsv('chi-regression.txt')
grk_measures <- read_tsv('grk-regression.txt')
jap_measures <- read_tsv('jap-regression.txt')
eng_measures_tidy <- eng_measures %>%
mutate(lang = 'English', freqToken = scale(freqToken), freqType = scale(freqType), flToken=scale(flToken), flType=scale(flType))
chi_measures_tidy <- chi_measures %>%
mutate(lang = 'Chinese', freqToken = scale(freqToken), freqType = scale(freqType), flToken=scale(flToken), flType=scale(flType))
grk_measures_tidy <- grk_measures %>%
mutate(lang = 'Greek', freqToken = scale(freqToken), freqType = scale(freqType), flToken=scale(flToken), flType=scale(flType))
jap_measures_tidy <-jap_measures %>%
mutate(lang = 'Japanese', freqToken = scale(freqToken), freqType = scale(freqType), flToken=scale(flToken), flType=scale(flType))
data_measures <-  eng_measures_tidy %>%
full_join(grk_measures_tidy) %>%
full_join(chi_measures_tidy) %>%
full_join(jap_measures_tidy)
data_measures <- data_measures %>%
rename(target=consonant)
eng <- read_tsv('up-eng.txt')
chi <- read_tsv('up-chi.txt')
grk <- read_tsv('up-grk.txt')
jap <- read_tsv('up-jpn.txt')
data <-  eng %>%
full_join(grk) %>%
full_join(chi) %>%
full_join(jap)
data_tidy <- data_measures %>%
inner_join(data, by='target') %>%
filter(correct!='m')
m1 = glmer(as.numeric(correct) ~ flType + (1|complexity) + (1|lang.x) + (1|age) + (1|word) + (1|child), family=binomial, data=data_tidy)
summary(m1)
m2 = glmer(as.numeric(correct) ~ flToken + (1|complexity)  + (1|lang.x) + (1|age) + (1|word) + (1|child), family=binomial, data=data_tidy)
summary(m2)
m3 = glmer(as.numeric(correct) ~ freqType + (1|complexity) + (1|lang.x) + (1|age) + (1|word) + (1|child), family=binomial, data=data_tidy)
summary(m3)
m4 = glmer(as.numeric(correct) ~ freqToken + (1|complexity)  + (1|lang.x) + (1|age) + (1|word) + (1|child), family=binomial, data=data_tidy)
summary(m4)
setwd("~/Documents/GitHub2/Functionalism_Contrast_Change/Chapter4/4.5")
library(ggplot2)
data_mp = read.table('data_mp.txt', head=TRUE)
ggplot(data_mp, aes(iter, mp, group=lang, color=lang)) +
geom_point(size=2.5, position=position_jitterdodge(jitter.width = 0.1, jitter.height=0.1)) +
ggtitle("Syllable contrasts in the vocabulary")+
geom_smooth() +
xlab("Words learned") +
ylab("Syllable contrasts") +
theme(plot.title = element_text(hjust = 0.5))
data_mp = read.table('data_mp.txt', head=TRUE)
ggplot(data_mp, aes(iter, mp, group=lang, color=lang)) +
geom_point(size=2.5, position=position_jitterdodge(jitter.width = 0.1, jitter.height=0.1)) +
ggtitle("Minimal Pairs /f/-/ θ/ in the vocabulary")+
geom_smooth() +
xlab("Words learned") +
ylab("Minimal Pairs") +
theme(plot.title = element_text(hjust = 0.5))
data_syl = read.table('data_syl.txt', head=TRUE)
ggplot(data_syl, aes(iter, mp, group=lang, color=lang)) +
geom_point(size=2.5, position=position_jitterdodge(jitter.width = 0.1, jitter.height=0.1)) +
ggtitle("Word-initial CV contrasts between /f/-/θ/ in the vocabulary")+
geom_smooth() +
xlab("Words learned") +
ylab("Syllable contrasts") +
theme(plot.title = element_text(hjust = 0.5))
data_mp = read.table('data_mp.txt', head=TRUE)
ggplot(data_mp, aes(iter, mp, group=lang, color=lang)) +
geom_point(size=2.5, position=position_jitterdodge(jitter.width = 0.1, jitter.height=0.1)) +
ggtitle("Minimal Pairs /f/-/ θ/ in the vocabulary")+
geom_smooth() +
xlab("Words learned") +
ylab("Minimal Pairs") +
theme_classic() +
theme(plot.title = element_text(hjust = 0.5))
data_syl = read.table('data_syl.txt', head=TRUE)
ggplot(data_syl, aes(iter, mp, group=lang, color=lang)) +
geom_point(size=2.5, position=position_jitterdodge(jitter.width = 0.1, jitter.height=0.1)) +
ggtitle("Word-initial CV contrasts between /f/-/θ/ in the vocabulary")+
geom_smooth() +
xlab("Words learned") +
ylab("Syllable contrasts") +
theme_classic() +
theme(plot.title = element_text(hjust = 0.5))
